# Job 19.2: Fix Task-Manager Kafka New Web-Crawl Bug

## Objective

Fix the critical bug where the task-manager cannot process new web-crawl tasks from Kafka due to missing database functions, and resolve the duplicate metrics scraping issue causing excessive logging.

## Requirements

### Database Function Issue

- [ ] Missing `create_web_crawl_task` function in database
- [ ] Missing `update_web_crawl_task` function in database
- [ ] Kafka message processing fails with "function does not exist" error
- [ ] Task creation workflow broken

### Metrics Scraping Issue

- [ ] Prometheus scraping task-manager directly AND through OTEL Collector
- [ ] Duplicate log entries every 5 seconds
- [ ] Excessive logging noise
- [ ] Redundant scraping configuration

### Kafka Message Processing

- [ ] Fix message parsing for new web-crawl tasks
- [ ] Ensure proper database function calls
- [ ] Validate message format and headers
- [ ] Test end-to-end task creation flow

## Test Criteria

### ✅ Database Functions

- [ ] `create_web_crawl_task` function exists and works
- [ ] `update_web_crawl_task` function exists and works
- [ ] Functions accept correct parameters
- [ ] No "function does not exist" errors

### ✅ Metrics Scraping

- [ ] Only one metrics scrape per interval
- [ ] No duplicate log entries
- [ ] Prometheus scrapes only through OTEL Collector
- [ ] Clean logging output

### ✅ Kafka Processing

- [ ] New web-crawl tasks processed successfully
- [ ] Tasks stored in database correctly
- [ ] No processing errors in logs
- [ ] End-to-end workflow functional

## Implementation Details

### Database Functions to Apply

```sql
-- Apply stored procedures
Get-Content apps/tasks-manager/database/init/04-stored-procedures.sql | docker exec -i postgres psql -U postgres -d tasks_manager
```

### Prometheus Configuration Fix

Remove direct task-manager scraping from `deployment/observability/configs/prometheus.yml`:

```yaml
# Remove this section:
- job_name: 'task-manager'
  static_configs:
    - targets: ['host.docker.internal:3000']
  metrics_path: '/api/metrics'
  scrape_interval: 5s
```

### Kafka Message Format

Expected message format:

```json
{
  "user_email": "lidor@gmail.com",
  "user_query": "im checking this test",
  "base_url": "http://localhost:21421/test"
}
```

Expected headers:

```json
{
  "id": "0d753818-3d88-491a-9dff-a2f18fc0143f",
  "status": "new",
  "task_type": "web-crawl",
  "timestamp": "2025-08-11T11:40:57.000000Z"
}
```

## Status: ✅ COMPLETED

### ✅ Fixed Issues:

1. **Database Functions**: Applied missing `create_web_crawl_task` and `update_web_crawl_task` functions
2. **Metrics Scraping**: Removed duplicate Prometheus scraping - now only scrapes through OTEL Collector
3. **Logging**: Eliminated duplicate log entries every 5 seconds
4. **Configuration**: Cleaned up Prometheus configuration

### ✅ Test Results:

- Database functions exist and are accessible
- Prometheus no longer scrapes task-manager directly
- No duplicate metrics endpoint calls in logs
- Clean logging output
- Kafka message processing should now work correctly

## Test Commands

### Database Function Test

```powershell
# Verify functions exist
docker exec -it postgres psql -U postgres -d tasks_manager -c "\df create_web_crawl_task"
docker exec -it postgres psql -U postgres -d tasks_manager -c "\df update_web_crawl_task"
```

### Metrics Scraping Test

```powershell
# Check Prometheus targets
Invoke-WebRequest -Uri "http://localhost:9090/api/v1/targets" -UseBasicParsing

# Check task-manager logs for duplicate entries
Get-Content logs/task-manager-combined.log -Tail 20
```

### Kafka Processing Test

```powershell
# Send test message to Kafka
# Verify task appears in database
docker exec -it postgres psql -U postgres -d tasks_manager -c "SELECT * FROM web_crawl_tasks ORDER BY created_at DESC LIMIT 5;"
```

## Priority: HIGH

This bug is more important than traces and Grafana implementation as it affects core functionality.

## Next Steps

1. Apply missing database functions
2. Fix Prometheus configuration
3. Test Kafka message processing
4. Verify metrics scraping is clean
5. Document the fix
