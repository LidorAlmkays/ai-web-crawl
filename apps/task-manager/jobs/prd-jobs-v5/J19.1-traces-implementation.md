# Job 19.1: Distributed Tracing Implementation with Tempo

## Objective

Implement distributed tracing in the task-manager application using OpenTelemetry and Tempo, enabling end-to-end trace visibility directly in Grafana across all operations including Kafka message processing, database operations, and HTTP requests.

## Status: üîÑ IN PROGRESS

## Sub-Jobs Structure

### Sub-Job 19.1.1: OpenTelemetry SDK Setup and Configuration

**Status**: ‚è≥ PENDING

#### Requirements

- [ ] Install OpenTelemetry packages for Node.js
- [ ] Create OTEL initialization configuration
- [ ] Set up auto-instrumentation for HTTP, Express, PostgreSQL, KafkaJS
- [ ] Configure trace sampling and export settings
- [ ] Initialize OTEL SDK in application startup

#### Test Criteria

- [ ] Application starts without OTEL errors
- [ ] OTEL SDK is properly initialized
- [ ] Auto-instrumentation is loaded correctly
- [ ] Trace context is available in application
- [ ] No TypeScript compilation errors

#### Files to Create/Modify

- `apps/task-manager/src/common/utils/otel-init.ts` (re-enable and fix)
- `apps/task-manager/src/config/tracing.ts` (new)
- `apps/task-manager/src/app.ts` (add OTEL initialization)
- `package.json` (add OTEL dependencies)

### Sub-Job 19.1.2: HTTP Request Tracing

**Status**: ‚è≥ PENDING

#### Requirements

- [ ] Add trace instrumentation to REST API endpoints
- [ ] Propagate trace context in HTTP headers
- [ ] Add custom spans for business logic operations
- [ ] Include request metadata in traces
- [ ] Handle trace context in error scenarios

#### Test Criteria

- [ ] HTTP requests generate traces with proper spans
- [ ] Trace context is propagated in headers
- [ ] Custom spans are created for business operations
- [ ] Error scenarios create error spans
- [ ] Trace IDs are included in logs

#### Files to Create/Modify

- `apps/task-manager/src/api/rest/rest.router.ts` (add tracing)
- `apps/task-manager/src/api/rest/middleware/tracing.middleware.ts` (new)
- `apps/task-manager/src/common/utils/trace-utils.ts` (new)

### Sub-Job 19.1.3: Kafka Operations Tracing

**Status**: ‚è≥ PENDING

#### Requirements

- [ ] Add trace instrumentation to Kafka message publishing
- [ ] Add trace instrumentation to Kafka message consumption
- [ ] Propagate trace context in Kafka message headers
- [ ] Create spans for message processing operations
- [ ] Handle trace context in Kafka error scenarios

#### Test Criteria

- [ ] Kafka message publishing creates traces
- [ ] Kafka message consumption creates traces
- [ ] Trace context is propagated in message headers
- [ ] Message processing operations are traced
- [ ] Kafka errors create error spans

#### Files to Create/Modify

- `apps/task-manager/src/api/kafka/handlers/task-status/complete-task.handler.ts`
- `apps/task-manager/src/api/kafka/handlers/task-status/error-task.handler.ts`
- `apps/task-manager/src/common/clients/kafka-client.ts`
- `apps/task-manager/src/api/kafka/kafka.factory.ts`

### Sub-Job 19.1.4: Database Operations Tracing

**Status**: ‚è≥ PENDING

#### Requirements

- [ ] Add trace instrumentation to PostgreSQL operations
- [ ] Create spans for SQL function calls
- [ ] Include query parameters in trace metadata
- [ ] Handle database errors in traces
- [ ] Add performance metrics to database spans

#### Test Criteria

- [ ] Database queries create traces with spans
- [ ] SQL function calls are properly traced
- [ ] Query parameters are included in trace metadata
- [ ] Database errors create error spans
- [ ] Performance metrics are available in traces

#### Files to Create/Modify

- `apps/task-manager/src/infrastructure/persistence/postgres/adapters/WebCrawlMetricsAdapter.ts`
- `apps/task-manager/src/infrastructure/persistence/postgres/postgres.factory.ts`
- `apps/task-manager/src/infrastructure/persistence/postgres/adapters/__tests__/WebCrawlMetricsAdapter.spec.ts`

### Sub-Job 19.1.5: Business Logic Tracing

**Status**: ‚è≥ PENDING

#### Requirements

- [ ] Add trace instrumentation to application layer services
- [ ] Create spans for metrics calculation operations
- [ ] Add trace context to health check operations
- [ ] Include business logic metadata in traces
- [ ] Handle business logic errors in traces

#### Test Criteria

- [ ] Application services create meaningful spans
- [ ] Metrics calculations are properly traced
- [ ] Health checks include trace context
- [ ] Business logic metadata is available in traces
- [ ] Business errors create error spans

#### Files to Create/Modify

- `apps/task-manager/src/application/metrics/services/WebCrawlMetricsService.ts`
- `apps/task-manager/src/common/health/health-check.service.ts`
- `apps/task-manager/src/application/services/application.factory.ts`

### Sub-Job 19.1.6: Tempo Integration and Configuration

**Status**: ‚è≥ PENDING

#### Requirements

- [ ] Add Tempo to observability stack
- [ ] Configure OTEL Collector to export traces to Tempo
- [ ] Configure Grafana to use Tempo as data source
- [ ] Test trace flow: Application ‚Üí OTEL Collector ‚Üí Tempo ‚Üí Grafana
- [ ] Verify trace sampling and processing

#### Test Criteria

- [ ] Tempo container starts successfully
- [ ] OTEL Collector exports traces to Tempo via OTLP
- [ ] Grafana can query Tempo for traces
- [ ] Traces are visible in Grafana UI
- [ ] No trace processing errors in logs

#### Files to Create/Modify

- `deployment/observability/docker-compose.yml` (add Tempo service)
- `deployment/observability/configs/otel-collector.yaml` (update traces pipeline)
- `deployment/observability/configs/grafana/provisioning/datasources/tempo.yml` (new)
- `deployment/observability/configs/tempo/tempo.yml` (new)

### Sub-Job 19.1.7: Grafana Tempo Integration and Verification

**Status**: ‚è≥ PENDING

#### Requirements

- [ ] Configure Tempo data source in Grafana
- [ ] Test trace visualization in Grafana UI
- [ ] Verify trace search and filtering functionality
- [ ] Test trace retention and storage
- [ ] Validate trace correlation across operations

#### Test Criteria

- [ ] Traces are visible in Grafana UI (http://localhost:3001)
- [ ] Trace search works for service name "task-manager"
- [ ] Individual spans show operation details
- [ ] Trace timeline shows operation flow
- [ ] Error traces are properly marked

#### Files to Create/Modify

- `deployment/observability/configs/grafana/provisioning/datasources/datasources.yml` (add Tempo)
- `scripts/test-tempo-integration.js` (new)
- `deployment/observability/README.md` (update with Tempo info)

### Sub-Job 19.1.8: End-to-End Tracing Validation

**Status**: ‚è≥ PENDING

#### Requirements

- [ ] Test complete request flow tracing
- [ ] Verify Kafka message processing traces
- [ ] Validate database operation traces
- [ ] Test error scenario tracing
- [ ] Verify trace correlation across all operations

#### Test Criteria

- [ ] Complete request flow is traceable end-to-end
- [ ] Kafka message processing is fully traced
- [ ] Database operations are properly traced
- [ ] Error scenarios create comprehensive traces
- [ ] Trace correlation works across all operations

#### Files to Create/Modify

- `apps/task-manager/src/api/rest/__tests__/tracing-integration.spec.ts` (new)
- `scripts/test-end-to-end-tracing.js` (new)

## Implementation Details

### Required Packages

```json
{
  "@opentelemetry/api": "^1.7.0",
  "@opentelemetry/sdk-node": "^0.48.0",
  "@opentelemetry/auto-instrumentations-node": "^0.40.0",
  "@opentelemetry/exporter-otlp-http": "^0.48.0",
  "@opentelemetry/instrumentation-http": "^0.48.0",
  "@opentelemetry/instrumentation-express": "^0.33.0",
  "@opentelemetry/instrumentation-pg": "^0.33.0",
  "@opentelemetry/instrumentation-kafkajs": "^0.33.0"
}
```

### OTEL Configuration

- **Service Name**: `task-manager`
- **Environment**: `development`
- **OTLP Endpoint**: `http://localhost:4318` (HTTP)
- **Sampling**: 100% for development
- **Auto-instrumentation**: Enable for HTTP, Express, PostgreSQL, KafkaJS

### Trace Flow Architecture

```
Task Manager ‚Üí OTEL Collector ‚Üí Tempo ‚Üí Grafana
     ‚Üì              ‚Üì           ‚Üì        ‚Üì
  Generate      Process &    Store &   Visualize
   Traces       Export      Query      Traces
```

### Trace Points

1. **HTTP Requests**: All REST API endpoints (`/api/metrics`, `/api/health`, etc.)
2. **Kafka Operations**: Message publishing and consumption in task status handlers
3. **Database Operations**: All PostgreSQL function calls (metrics queries)
4. **Business Logic**: Metrics calculation, health checks, task processing
5. **Error Handling**: Exception tracing and error spans

### Expected Trace Structure

```
HTTP Request (GET /api/metrics)
‚îú‚îÄ‚îÄ Database Query (get_web_crawl_metrics)
‚îú‚îÄ‚îÄ Business Logic (calculate metrics)
‚îî‚îÄ‚îÄ Response Generation

Kafka Message (task-status)
‚îú‚îÄ‚îÄ Message Processing
‚îú‚îÄ‚îÄ Database Update
‚îî‚îÄ‚îÄ Response Handling
```

## Dependencies

- **OTEL Collector**: Already configured and running
- **Tempo**: Will be added to observability stack
- **Prometheus**: Already configured and running
- **Grafana**: Needs to be fixed (see Job 20: Fix Grafana Docker Issue)

## Success Metrics

- [ ] All HTTP requests generate traces
- [ ] All Kafka operations are traced
- [ ] All database operations are traced
- [ ] Traces are visible in Grafana UI via Tempo
- [ ] Trace correlation works across operations
- [ ] Error scenarios are properly traced
- [ ] No performance degradation from tracing
- [ ] All sub-jobs pass their test criteria

## Next Steps

1. Start with Sub-Job 19.1.1: OpenTelemetry SDK Setup
2. Progress through each sub-job sequentially
3. Test each sub-job thoroughly before proceeding
4. Validate end-to-end tracing in Sub-Job 19.1.8
5. Document any issues and solutions
